{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline is the boss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data, create listings dataframe\n",
    "path = '../data/dc-airbnb/'\n",
    "listings_csv = os.path.join(path,'listings.csv.gz')\n",
    "#print(listings_csv)\n",
    "listings = pd.read_csv(listings_csv, index_col = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all dollars fields\n",
    "#function\n",
    "def fix_currency(row):\n",
    "    row = row.replace(',', '')\n",
    "    row = row.replace('$', '')\n",
    "    return row\n",
    "\n",
    "# #update rows and convert to boolean, only non null values\n",
    "Currency_columns = ['extra_people', 'cleaning_fee', 'security_deposit', 'price']\n",
    "\n",
    "for column in Currency_columns:\n",
    "    filt = listings[column].notna()\n",
    "    listings[column] = listings[column][filt].apply(lambda col: fix_currency(col)).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bool(row):\n",
    "    row = row.replace('f', '0')\n",
    "    row = row.replace('t', '1')\n",
    "    return row\n",
    "\n",
    "# #update rows and convert to boolean, only non null values\n",
    "Boolean_columns = ['host_is_superhost', 'is_location_exact', 'instant_bookable', 'host_identity_verified']\n",
    "\n",
    "for column in Boolean_columns:\n",
    "    filt = listings[column].notna()\n",
    "    listings[column] = listings[column][filt].apply(lambda col: convert_bool(col)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver to date first then number, only do for non null\n",
    "listings['host_since'] = pd.to_datetime(listings['host_since'])\n",
    "\n",
    "filt = listings['host_since'].notna()\n",
    "listings['host_since'] = listings['host_since'][filt].apply(lambda x: x.toordinal())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Rows\n",
    "Based on previous analyisis: \n",
    " 1. Records with reviews within one year\n",
    " 2. Rmove all hotels property type\n",
    " 3. Limit price range (0-$800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many records got reviews last 1 year\n",
    "scraped_date = datetime.strptime('2020-03-14',\"%Y-%m-%d\")\n",
    "listings['last_review_days_ago'] = (scraped_date - pd.to_datetime(listings['last_review'])).dt.days\n",
    "filt = listings['last_review_days_ago'] <= 365\n",
    "listings['property_type'][filt].count()\n",
    "listings = listings[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping records with certain property type, mostly hotels\n",
    "filt = (~listings['property_type'].isin (['Aparthotel','Bed and breakfast','Boutique hotel',' Hostel', 'Hotel', 'Resort', 'Serviced apartment']))\n",
    "\n",
    "listings = listings[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit price\n",
    "filt = (listings['price'] > 0) & (listings['price'] < 500)\n",
    "listings = listings[filt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5363, 106)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          price\n",
      "cleaning_fee_yes_no            \n",
      "0                     94.894097\n",
      "1                    131.843117\n"
     ]
    }
   ],
   "source": [
    "#turn cleaning fee to yes and no column\n",
    "def cleaning_fee_yes_no (row):\n",
    "    if row['cleaning_fee'] > 0.00:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "listings['cleaning_fee_yes_no'] = listings.apply(cleaning_fee_yes_no, axis=1)\n",
    "\n",
    "print(listings.groupby('cleaning_fee_yes_no').agg({'price':'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              price\n",
      "security_deposit_yes_no            \n",
      "0                        114.214575\n",
      "1                        144.751980\n"
     ]
    }
   ],
   "source": [
    "#turn security deposit to yes and no column\n",
    "def security_deposit_yes_no (row):\n",
    "    if row['security_deposit'] > 0.00:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "listings['security_deposit_yes_no'] = listings.apply(security_deposit_yes_no, axis=1)\n",
    "\n",
    "print(listings.groupby('security_deposit_yes_no').agg({'price':'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          price\n",
      "extra_people_yes_no            \n",
      "0                    128.604366\n",
      "1                    127.367573\n"
     ]
    }
   ],
   "source": [
    "#turn extra people fee to yes and no\n",
    "def extra_people_yes_no (row):\n",
    "    if row['extra_people'] > 0.00:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "listings['extra_people_yes_no'] = listings.apply(extra_people_yes_no, axis=1)\n",
    "\n",
    "print(listings.groupby('extra_people_yes_no').agg({'price':'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "21088730    79\n",
      "10526371    66\n",
      "26708700    65\n",
      "33854482    65\n",
      "18791414    65\n",
      "Name: amenities_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#amenities_count\n",
    "\n",
    "listings['amenities_count'] = listings['amenities'].str.count(',')\n",
    "print (listings['amenities_count'].sort_values(ascending=False).head())\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='amenities', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_rate_calc\n",
      "0.0    1490\n",
      "1.0    3873\n",
      "Name: host_response_rate_calc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# host_response_rate\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    if row == '100%':\n",
    "        row = '1'\n",
    "    else: row = '0'\n",
    "    return row\n",
    "\n",
    "listings['host_response_rate_calc'] = listings['host_response_rate'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='host_response_rate', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('host_response_rate_calc')['host_response_rate_calc'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_acceptance_rate_calc\n",
      "0.0    3097\n",
      "1.0    2266\n",
      "Name: host_acceptance_rate_calc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#host_acceptance_rate\n",
    "#needs to use function that conver 100% to 1 and the rest to 0 (from previous cell)\n",
    "\n",
    "listings['host_acceptance_rate_calc'] = listings['host_acceptance_rate'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='host_acceptance_rate', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('host_acceptance_rate_calc')['host_acceptance_rate_calc'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_time_one_hour\n",
      "0.0    1474\n",
      "1.0    3889\n",
      "Name: host_response_time_one_hour, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# host_response_time\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    if row == 'within an hour':\n",
    "        row = '1'\n",
    "    else: row = '0'\n",
    "    return row\n",
    "\n",
    "listings['host_response_time_one_hour'] = listings['host_response_time'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='host_response_time', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('host_response_time_one_hour')['host_response_time_one_hour'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apt_yes_no\n",
      "0.0    3055\n",
      "1.0    2308\n",
      "Name: apt_yes_no, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#property_type, after modeling, loft seems to affect price. But looking at the data loft price is between 28 and 900 dollars.\n",
    "# I am going to split propety type into two, apt or non\n",
    "#listings.groupby('property_type').agg({'property_type': 'size', 'price':'max'}).sort_values(by='price',ascending=False)\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    if row == 'Apartment':\n",
    "        row = '1'\n",
    "    else: row = '0'\n",
    "    return row\n",
    "\n",
    "listings['apt_yes_no'] = listings['property_type'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='property_type', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('apt_yes_no')['apt_yes_no'].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_bed_yes_no\n",
      "0.0      49\n",
      "1.0    5314\n",
      "Name: real_bed_yes_no, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#bed_type --- may not be needed, let's see\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    if row == 'Real Bed':\n",
    "        row = '1'\n",
    "    else: row = '0'\n",
    "    return row\n",
    "\n",
    "listings['real_bed_yes_no'] = listings['bed_type'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='bed_type', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('real_bed_yes_no')['real_bed_yes_no'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancellation_policy_calc\n",
      "flexible    1167\n",
      "moderate    2156\n",
      "strict      2040\n",
      "Name: cancellation_policy_calc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#cancellation_policy -- let's do 3 classes (flexible, moderate, and strict)\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    row = row.replace('strict_14_with_grace_period', 'strict')\n",
    "    row = row.replace('super_strict_30', 'strict')\n",
    "    row = row.replace('super_strict_60', 'strict')\n",
    "    return row\n",
    "\n",
    "#new column\n",
    "listings['cancellation_policy_calc'] = listings['cancellation_policy'].apply(lambda col: convert_string_to_int(col))\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='cancellation_policy', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('cancellation_policy_calc')['cancellation_policy_calc'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_listings\n",
      "0.0     398\n",
      "1.0    4965\n",
      "Name: multiple_listings, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#host_listings_count\n",
    "\n",
    "def convert_string_to_int(row):\n",
    "    if row < 1:\n",
    "        row = 0\n",
    "    else: row = 1\n",
    "    return row\n",
    "\n",
    "listings['multiple_listings'] = listings['host_listings_count'].apply(lambda col: convert_string_to_int(col)).astype(float)\n",
    "\n",
    "# drop original column\n",
    "listings.drop(columns='host_listings_count', inplace = True)\n",
    "\n",
    "#check result\n",
    "print(listings.groupby('multiple_listings')['multiple_listings'].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "Optimus Prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['bathrooms', 'bedrooms', 'beds', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month', 'amenities_count', 'host_response_time_one_hour', 'host_response_rate_calc','host_acceptance_rate_calc','apt_yes_no','real_bed_yes_no','multiple_listings', 'host_is_superhost', 'is_location_exact', 'instant_bookable', 'host_identity_verified', 'host_since', 'accommodates', 'guests_included', 'cleaning_fee_yes_no','security_deposit_yes_no','extra_people_yes_no']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)), # strategy='median' \n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "categorical_features = ['neighbourhood_group_cleansed', 'room_type', 'cancellation_policy_calc']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = numeric_features + categorical_features\n",
    "features = listings[feature_list]\n",
    "\n",
    "target = listings['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_Lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('regressor', Lasso(alpha=0.5))\n",
    "                    ])\n",
    "\n",
    "pl_Gboost = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('regressor', GradientBoostingRegressor(random_state=0))\n",
    "                    ])\n",
    "\n",
    "pl_RandomForest = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('regressor', RandomForestRegressor(n_estimators=100, random_state=None, min_samples_split=100))\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=0,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=...\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['neighbourhood_group_cleansed',\n",
       "                                                   'room_type',\n",
       "                                                   'cancellation_policy_calc'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Lasso(alpha=0.5, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=1000, normalize=False, positive=False,\n",
       "                       precompute=False, random_state=None, selection='cyclic',\n",
       "                       tol=0.0001, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_Lasso.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880427979541197\n",
      "127.64777216918978\n",
      "0.6017102040400742\n"
     ]
    }
   ],
   "source": [
    "print(pl_Lasso.score(X_train, y_train))\n",
    "print(pl_Lasso.predict(X_test).mean().mean())\n",
    "print(pl_Lasso.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=0,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=...\n",
       "                                           init=None, learning_rate=0.1,\n",
       "                                           loss='ls', max_depth=3,\n",
       "                                           max_features=None,\n",
       "                                           max_leaf_nodes=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=1,\n",
       "                                           min_samples_split=2,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=100,\n",
       "                                           n_iter_no_change=None,\n",
       "                                           presort='auto', random_state=0,\n",
       "                                           subsample=1.0, tol=0.0001,\n",
       "                                           validation_fraction=0.1, verbose=0,\n",
       "                                           warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_Gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6966732631462602\n",
      "127.40494463195063\n",
      "0.6485727663303894\n"
     ]
    }
   ],
   "source": [
    "print(pl_Gboost.score(X_train, y_train))\n",
    "print(pl_Gboost.predict(X_test).mean().mean())\n",
    "print(pl_Gboost.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=0,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=...\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1,\n",
       "                                       min_samples_split=100,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_RandomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6578115689586137\n",
      "127.36145847146217\n",
      "0.6319367715733739\n"
     ]
    }
   ],
   "source": [
    "print(pl_RandomForest.score(X_train, y_train))\n",
    "print(pl_RandomForest.predict(X_test).mean().mean())\n",
    "print(pl_RandomForest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
